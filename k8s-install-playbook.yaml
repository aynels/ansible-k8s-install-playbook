# Ansible playbook to install the required packages on the master and worker nodes
# Based on https://github.com/tjtharrison/kubernetes-deploy/blob/main/install.yaml
- hosts: "kcontrol, workers"
  become: yes # Run as root

  tasks:
    - name: Configure containerd
      shell: |
        sudo tee /etc/modules-load.d/containerd.conf <<EOF
        overlay
        br_netfilter
        EOF
        sudo modprobe overlay
        sudo modprobe br_netfilter
    - name: Configure kernel
      shell: |
        sudo tee /etc/sysctl.d/kubernetes.conf <<EOF
        net.bridge.bridge-nf-call-ip6tables = 1
        net.bridge.bridge-nf-call-iptables = 1
        net.ipv4.ip_forward = 1
        EOF
    - name: Apply changes
      shell: sudo sysctl --system
    - name: Update syatem
      shell: sudo apt-get update
    - name: Install containerd dependencies
      apt:
        name: [ 'apt-transport-https','ca-certificates','curl','gnupg-agent','software-properties-common' ]
        state: present
        update_cache: yes
    - name: Add containerd gpg key
      apt_key:
        url: https://download.docker.com/linux/ubuntu/gpg
        state: present
    - name: Add containerd software repository
      apt_repository:
        repo: deb [arch=amd64] https://download.docker.com/linux/ubuntu jammy stable
        state: present
        filename: docker.list
        update_cache: yes
    - name: Install containerd
      apt:
        name: [ 'containerd.io' ]
        state: present
        update_cache: yes
    - name: Configure containerd
      shell: |
        sudo mkdir -p /etc/containerd
        sudo containerd config default | sudo tee /etc/containerd/config.toml
        sudo sed -i 's/SystemdCgroup \= false/SystemdCgroup \= true/g' /etc/containerd/config.toml
    - name: Restart and enable containerd
      systemd:
        name: containerd
        state: restarted
        enabled: yes
    - name: Disable swap
      shell: swapoff -a
    - name: Stop swap from mounting
      shell: sed -i 's/^\/swap/#\/swap/g' /etc/fstab
    - name: Install dependencies
      apt:
        name: [ 'apt-transport-https','ca-certificates','curl','gnupg-agent','software-properties-common' ]
        state: present
        update_cache: yes
    - name: Add Kubernetes gpg key
      apt_key:
        url: https://packages.cloud.google.com/apt/doc/apt-key.gpg
        state: present
    - name: Add Kubernetes software repository
      apt_repository:
        repo: deb https://apt.kubernetes.io/ kubernetes-xenial main
        state: present
        filename: kubernetes.list
        update_cache: yes
    - name: Install kubernetes
      apt:
        name: [ 'kubelet','kubeadm','kubectl' ]
        state: present
        update_cache: yes
    - name: Hold kubelet package at current version
      ansible.builtin.dpkg_selections:
        name: 'kubelet'
        selection: hold
    - name: Hold kubeadm package at current version
      ansible.builtin.dpkg_selections:
        name: 'kubeadm'
        selection: hold
    - name: Hold kubectl package at current version
      ansible.builtin.dpkg_selections:
        name: 'kubectl'
        selection: hold
    # Setup isci for Longhorn
    - name: Install iscsi and nfs-common
      apt:
        name: [ 'open-iscsi', 'nfs-common' ]
        state: present
        update_cache: yes

# Ansible playbook to initialize the master node
- hosts: kcontrol
  become: yes # Run as root

  tasks:
    - name: Add the user 'k8sadmin' with group 'k8sadmin'
      ansible.builtin.group:
        name: k8sadmin
        state: present
    - name: Add the user 'k8sadmin' with group 'k8sadmin'
      ansible.builtin.user:
        name: k8sadmin
        group: k8sadmin
    - name: Check if the master node is already initialized
      stat:
        path: /etc/kubernetes/admin.conf
      register: kubeadm_init
    - name: Initialize the master node
      command: kubeadm init --pod-network-cidr=192.168.1.0/24
      when: kubeadm_init.stat.exists == false # Only run if the master node is not already initialized
      register: kubernetes_init_command
    - name: Display registered kubeadm init output
      debug:
        var: kubernetes_init_command.stdout_lines
    - name: Create .kube directory
      file:
        path: /home/k8sadmin/.kube
        state: directory
        owner: k8sadmin
        group: k8sadmin
        mode: 0755
      when: kubeadm_init.stat.exists == false # Only run if the master node is not already initialized
    - name: Copy the kube config file
      copy:
        src: /etc/kubernetes/admin.conf
        dest: /home/k8sadmin/.kube/config
        remote_src: yes
        owner: k8sadmin
        group: k8sadmin
        mode: 0644
      when: kubeadm_init.stat.exists == false # Only run if the master node is not already initialized

    - name: Install calico CNI
      command: kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
      become: yes
      become_user: k8sadmin
    - name: Get the token for joining the worker nodes
      become: yes
      become_user: k8sadmin
      shell: kubeadm token create  --print-join-command
      register: kubernetes_join_command
    - name: Display registered output
      debug:
        var: kubernetes_join_command.stdout_lines
    # Setup Longhorn
    - name: Remove taint from master node to allow disk replication
      command: kubectl taint nodes --all node-role.kubernetes.io/control-plane-
      become: yes
      become_user: k8sadmin
    - name: Install Longhorn
      command: kubectl apply -f https://raw.githubusercontent.com/longhorn/longhorn/v1.5.3/deploy/longhorn.yaml
      become: yes
      become_user: k8sadmin
    - name: Create dummy host to store variable for node config
      add_host:
        name: "DUMMY_HOST"
        JOIN_COMMAND: "{{ kubernetes_join_command.stdout_lines[0] }}"

# Ansible playbook to join the worker nodes to the cluster
- hosts: workers
  become: yes # Run as root

  tasks:
    - name: Check if the worker node is already joined
      stat:
        path: /etc/kubernetes/kubelet.conf
      register: kubeadm_join
    - name: Join the worker nodes to the cluster
      command: "{{ hostvars['DUMMY_HOST']['JOIN_COMMAND'] }}"
      become: yes
      when: kubeadm_join.stat.exists == false # Only run if the worker node is not already joined


# To be able to manage the cluster from the master node, follow the below steps
#mkdir -p $HOME/.kube
#sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
#sudo chown $(id -u):$(id -g) $HOME/.kube/config
